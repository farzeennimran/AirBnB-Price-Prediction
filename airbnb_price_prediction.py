# -*- coding: utf-8 -*-
"""Airbnb Price Prediction.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1710w9gY76si2_Wj-Hbh-MWOH8hfoqykl

# **Airbnb Price Prediction**

# Loading the Dataset
"""

import pandas as pd
df=pd.read_csv("train.csv")
df

df.info()

"""### **Total features:** 28

  ### **Total instances:** 43665

### **Target Variable: log_price**

"""

df.describe()

"""## Importing the Libraries"""

import numpy as np
import seaborn as sns
from sklearn.svm import SVR
import matplotlib.pyplot as plt
from sklearn.metrics import make_scorer
from sklearn.feature_selection import RFE
from sklearn.metrics import accuracy_score
from sklearn.feature_selection import RFECV
from sklearn.linear_model import BayesianRidge
from sklearn.tree import DecisionTreeRegressor
from sklearn.preprocessing import LabelEncoder
from sklearn.neighbors import KNeighborsRegressor
from sklearn.model_selection import cross_val_score
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn.feature_selection import SelectKBest, mutual_info_regression
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score

"""## Visualization"""

plt.figure(figsize=(10, 6))
plt.hist(df['log_price'], bins=20, color='skyblue', edgecolor='black')
plt.title('Histogram of Log Price')
plt.xlabel('Target variable: log price')
plt.ylabel('Count')
plt.show()

plt.figure(figsize=(10, 6))
plt.scatter(df.index, df['log_price'], color='skyblue', alpha=0.5)
plt.title('Scatter Plot of Log Price')
plt.xlabel('Index')
plt.ylabel('Target variable: log price')
plt.show()

city_counts = df['city'].value_counts()
plt.figure(figsize=(10, 6))
city_counts.plot(kind='bar', color='skyblue')
plt.title('City Distribution')
plt.xlabel('City')
plt.ylabel('Count')
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()

df['host_has_profile_pic'].value_counts()

plt.figure(figsize=(8, 6))
df['host_has_profile_pic'].value_counts().plot(kind='bar', color='skyblue')
plt.title('Distribution of host_has_profile_pic')
plt.xlabel('Host has profile picture?')
plt.ylabel('Count')
plt.xticks(rotation=0)
plt.show()

df['bed_type'].value_counts()

plt.figure(figsize=(8, 6))
df['bed_type'].value_counts().plot(kind='bar', color='lightgreen')
plt.title('Distribution of bed_type')
plt.xlabel('Bed type')
plt.ylabel('Count')
plt.xticks(rotation=45)
plt.show()

df['bathrooms'].value_counts()

plt.figure(figsize=(10, 6))
df['bathrooms'].hist(color='salmon', bins=20)
plt.title('Distribution of bathrooms')
plt.xlabel('Number of bathrooms')
plt.ylabel('Frequency')
plt.show()

df['cleaning_fee'].value_counts()

plt.figure(figsize=(8, 6))
df['cleaning_fee'].value_counts().plot(kind='bar', color='skyblue')
plt.title('Distribution of host_has_profile_pic')
plt.xlabel('Host has profile picture?')
plt.ylabel('Count')
plt.xticks(rotation=0)
plt.show()

plt.figure(figsize=(10, 6))
plt.hist(df['beds'], bins=20, color='skyblue', edgecolor='black')
plt.title('Distribution of Beds')
plt.xlabel('Beds')
plt.ylabel('Frequency')
plt.show()

room_type_counts = df['room_type'].value_counts()
plt.figure(figsize=(8, 8))
plt.pie(room_type_counts, labels=room_type_counts.index, autopct='%1.1f%%', startangle=140)
plt.title('Room Types Distribution')
plt.axis('equal')
plt.show()

df=df.drop(columns=['thumbnail_url', 'zipcode'])

df

df = df.sample(n=10000, random_state=42)

df

"""# Preprocessing"""

df.isna().sum()

"""### Filling in missing values"""

df["bathrooms"] = df['bathrooms'].fillna(round(df["bathrooms"].median()))

df["beds"] = df['beds'].fillna(round(df["beds"].median()))

df["bedrooms"] = df['bedrooms'].fillna(round(df["bedrooms"].median()))

df["review_scores_rating"] = df["review_scores_rating"].fillna((df["review_scores_rating"].median()))

# Fill missing values for categorical columns with mode
categorical_columns = ['host_identity_verified', 'neighbourhood', 'host_response_rate', 'host_since']
for col in categorical_columns:
  df[col].fillna(df[col].mode()[0], inplace=True)

# Fill missing values for categorical columns with mode
categorical_columns = ['last_review', 'first_review', 'host_identity_verified', 'host_has_profile_pic']
for col in categorical_columns:
  df[col].fillna(df[col].mode()[0], inplace=True)

df.isna().sum()

df['neighbourhood'].value_counts()

"""### Label Encodng for Categorical Data"""

from sklearn.preprocessing import LabelEncoder

label_encoder = LabelEncoder()

# Apply label encoding to 'bed_type'
df['bed_type_encoded'] = label_encoder.fit_transform(df['bed_type'])
df['cancellation_policy_encoded'] = label_encoder.fit_transform(df['cancellation_policy'])
df['property_type_encoded'] = label_encoder.fit_transform(df['property_type'])
df['room_type_encoded'] = label_encoder.fit_transform(df['room_type'])
df['city_encoded'] = label_encoder.fit_transform(df['city'])
df['neighbourhood_encoded'] = label_encoder.fit_transform(df['neighbourhood'])

df['bed_type_encoded']


df=df.drop(columns=['bed_type', 'cancellation_policy','name'])

df=df.drop(columns=['property_type', 'room_type','city', 'neighbourhood'])

"""### Bool to int"""

df['cleaning_fee'] = df['cleaning_fee'].astype(int)
df['host_has_profile_pic'] = df['host_has_profile_pic'].map({'t': True, 'f': False})
df['host_identity_verified'] = df['host_identity_verified'].map({'t': True, 'f': False})
df['instant_bookable'] = df['instant_bookable'].map({'t': True, 'f': False})

# Convert boolean values to integer (0 or 1)
df['host_has_profile_pic'] = df['host_has_profile_pic'].astype(int)
df['host_identity_verified'] = df['host_identity_verified'].astype(int)
df['instant_bookable'] = df['instant_bookable'].astype(int)

"""### % Values to numerical"""

df['host_response_rate'] = df['host_response_rate'].str.rstrip('%').astype(float) / 100.0

"""### Date format to Days conversion"""

df['host_since'] = pd.to_datetime(df['host_since'])
earliest_date = df['host_since'].min()
df['host_since_days'] = (df['host_since'] - earliest_date).dt.days

# Drop the original 'host_since' column
df.drop(columns=['host_since'], inplace=True)

df['first_review'] = pd.to_datetime(df['first_review'])
earliest_date = df['first_review'].min()
df['first_review_days'] = (df['first_review'] - earliest_date).dt.days

df.drop(columns=['first_review'], inplace=True)

df['last_review'] = pd.to_datetime(df['last_review'])
earliest_date = df['last_review'].min()
df['last_review_days'] = (df['last_review'] - earliest_date).dt.days

# Drop the original 'host_since' column
df.drop(columns=['last_review'], inplace=True)

"""### Converting amenities into no of availible amenities in each instance"""

df['amenities']

amenities_count = []
for i in df["amenities"]:
    amenities_count.append(len(i))

len(amenities_count)

df["amenities"] = amenities_count

df.amenities

df

df=df.drop(columns='description')

df

"""# Preprocessed all features into int or float data"""

df.info()

"""## Saving the preprocessed data"""

df.to_csv('processed_data.csv', index=False)

"""# Distribution of all Features"""

df.hist(edgecolor="black", linewidth=1.2, figsize=(30, 30));

df.corr()

import seaborn as sns
import matplotlib.pyplot as plt

sns.set(font_scale=2.25)
plt.figure(figsize=(50,50))
sns.heatmap(df.corr(), annot=True)
plt.savefig("heatmap_of_correlation_matrix.png")

"""# Feature Selection using Filter Based method

### Correlation Analysis
"""

corr_matrix = df.corr()

# Identify features with high correlation with the target variable
high_corr_features = corr_matrix['log_price'].abs().sort_values(ascending=False).index

selected_features_filter = high_corr_features[1:19]

selected_features_filter

"""### Wrapper Methods (Recursive Feature Elimination)"""

from sklearn.feature_selection import RFE
from sklearn.linear_model import LinearRegression

X = df.drop(columns=['log_price'])  # Features
y = df['log_price']  # Target variable

# Initialize the model and RFE
model = LinearRegression()
rfe = RFE(model, n_features_to_select=19)

rfe.fit(X, y)

selected_features_wrapper = X.columns[rfe.support_]

print("Selected Features (RFE):", selected_features_wrapper.tolist())

"""### Regularization (Lasso)"""

from sklearn.linear_model import Lasso

lasso = Lasso(alpha=0.1)

lasso.fit(X, y)

selected_features_embedded = X.columns[lasso.coef_ != 0]
selected_features_embedded

"""### Random Forest"""

from sklearn.ensemble import RandomForestRegressor

rf = RandomForestRegressor()
rf.fit(X, y)

feature_importances = pd.Series(rf.feature_importances_, index=X.columns)
# Select top features based on importance
selected_features_embedded = feature_importances.sort_values(ascending=False).index[:19]
selected_features_embedded

import pandas as pd
df=pd.read_csv("processed_data.csv")
df

"""# SVR(SUPPORT VECTOR REGRESSION)"""

# Data Splitting
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

#Feature Scaling
from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Model Training
from sklearn.svm import SVR

svr = SVR(kernel='linear')
svr.fit(X_train_scaled, y_train)

#Evaluation
from sklearn.metrics import mean_squared_error, r2_score

y_pred = svr.predict(X_test_scaled)
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

print(f'MSE: {mse}')
print(f'R-squared: {r2}')

from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error

maeValue = mean_absolute_error(y_test, y_pred)
print(f'MAE: {maeValue}')

# Let's predict prices for 5 new data points :)
import pandas as pd

y_test = y_test.reset_index(drop=True)
X_test_scaled = pd.DataFrame(X_test_scaled).reset_index(drop=True)

randomIndex = y_test.sample(5, random_state=42).index
actual = y_test.loc[randomIndex].tolist()
predicted = svr.predict(X_test_scaled.loc[randomIndex].values)

comparison = pd.DataFrame({
    'Actual': actual,
    'Predicted': predicted
}, index=randomIndex)

print(comparison)

import matplotlib.pyplot as plt

plt.scatter(y_test, y_pred, color='skyblue', label='Actual vs. Predicted')
plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], color='lightpink', linestyle='--', linewidth=2, label='Line of Best Fit')
plt.xlabel('Actual Log Price')
plt.ylabel('Predicted Log Price')
plt.title('SVR: Actual vs. Predicted Log Price')
plt.legend()
plt.show()

import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np

sns.set_palette("pastel")

plt.figure(figsize=(6, 6))
plt.scatter(np.arange(len(actual)), actual, color='lightpink', label='Actual')
plt.scatter(np.arange(len(predicted)), predicted, color='orange', label='Predicted')

plt.title('Comparison of Actual and Predicted Values')
plt.xlabel('Index')
plt.ylabel('Values')
plt.legend()

plt.show()

"""**ON SELECTED FEATURES**"""

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.svm import SVR
from sklearn.metrics import mean_squared_error, r2_score

corr_matrix = df.corr()

high_corr_features = corr_matrix['log_price'].abs().sort_values(ascending=False).index

selected_features_filter = high_corr_features[1:22]

X_filtered = df[selected_features_filter]
y = df['log_price']
X_train_filtered, X_test_filtered, y_train, y_test = train_test_split(X_filtered, y, test_size=0.2, random_state=42)

scaler = StandardScaler()
X_train_filtered_scaled = scaler.fit_transform(X_train_filtered)
X_test_filtered_scaled = scaler.transform(X_test_filtered)

svr_model = SVR(kernel='linear')
svr_model.fit(X_train_filtered_scaled, y_train)

y_pred_filtered = svr_model.predict(X_test_filtered_scaled)
mse_filtered = mean_squared_error(y_test, y_pred_filtered)
r2_filtered = r2_score(y_test, y_pred_filtered)

print(f'MSE (Filtered Features): {mse_filtered}')
print(f'R-squared (Filtered Features): {r2_filtered}')

from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error

maeValue = mean_absolute_error(y_test,y_pred_filtered)
print(f'MAE: {maeValue}')

y_test = y_test.reset_index(drop=True)
X_test_filtered_scaled  = pd.DataFrame(X_test_filtered_scaled ).reset_index(drop=True)

random_indices = y_test.sample(5, random_state=42).index

actual_prices = y_test.loc[random_indices].tolist()

predicted_prices = svr_model.predict(X_test_filtered_scaled .loc[random_indices].values)

comparison_df = pd.DataFrame({
    'Actual Log Price': actual_prices,
    'Predicted Log Price': predicted_prices
}, index=random_indices)

print(comparison_df)

import matplotlib.pyplot as plt

plt.scatter(y_test, y_pred_filtered, color='saddlebrown', label='Actual vs. Predicted')
plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], color='black', linestyle='--', linewidth=2, label='Line of Best Fit')
plt.xlabel('Actual Log Price')
plt.ylabel('Predicted Log Price')
plt.title('SVR: Actual vs. Predicted Log Price')
plt.legend()
plt.show()

import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np

sns.set_palette("pastel")

plt.figure(figsize=(6, 6))
plt.scatter(np.arange(len(actual_prices)), actual_prices, color='purple', label='Actual')
plt.scatter(np.arange(len(predicted_prices)), predicted_prices, color='green', label='Predicted')

plt.title('Comparison of Actual and Predicted Values')
plt.xlabel('Index')
plt.ylabel('Values')
plt.legend()

plt.show()

"""**Performing Hyper Parameter Tuning**"""

from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.preprocessing import StandardScaler
from sklearn.svm import SVR
from sklearn.metrics import mean_squared_error, r2_score

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Scaling the features
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

#  Defining the SVR model and parameter grid
svr = SVR()
param_grid = {
    'C': [0.1,0.001,0.001, 1],
    'gamma': ['scale', 'auto'],
    'kernel': ['linear', 'rbf', 'poly']
}

#performing grid search
grid_search = GridSearchCV(svr, param_grid, cv=3, scoring='r2', verbose=1)
grid_search.fit(X_train_scaled, y_train)

print(f'Best Parameters: {grid_search.best_params_}')
print(f'Best R-squared: {grid_search.best_score_}')

best_svr = grid_search.best_estimator_
y_pred = best_svr.predict(X_test_scaled)

mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

print(f'MSE: {mse}')
print(f'R-squared: {r2}')

from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error

maeValue = mean_absolute_error(y_test, y_pred)
print(f'MAE: {maeValue}')

import pandas as pd

y_test = y_test.reset_index(drop=True)
X_test_scaled = pd.DataFrame(X_test_scaled).reset_index(drop=True)

randomIndex = y_test.sample(5, random_state=42).index
actual = y_test.loc[randomIndex].tolist()
predicted = best_svr.predict(X_test_scaled.loc[randomIndex].values)

comparison = pd.DataFrame({
    'Actual': actual,
    'Predicted': predicted
}, index=randomIndex)

print(comparison)

import matplotlib.pyplot as plt

plt.scatter(y_test, y_pred, color='lightpink', label='Actual vs. Predicted')
plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], color='red', linestyle='--', linewidth=2, label='Line of Best Fit')
plt.xlabel('Actual Log Price')
plt.ylabel('Predicted Log Price')
plt.title('SVR: Actual vs. Predicted Log Price')
plt.legend()
plt.show()

import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np

sns.set_palette("pastel")

plt.figure(figsize=(6, 6))
plt.scatter(np.arange(len(actual)), actual, color='lightpink', label='Actual')
plt.scatter(np.arange(len(predicted)), predicted, color='red', label='Predicted')

plt.title('Comparison of Actual and Predicted Values')
plt.xlabel('Index')
plt.ylabel('Values')
plt.legend()

plt.show()

"""# LINEAR REGRESSION"""

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error

Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, test_size=0.2, random_state=42)

# scaling
scale = StandardScaler()
XtrainScaled = scale.fit_transform(Xtrain)
XtestScaled = scale.transform(Xtest)

# training of linear regression model
linear = LinearRegression()
linear.fit(XtrainScaled, ytrain)

ypred = linear.predict(XtestScaled)

# Evaluation
mseValue = mean_squared_error(ytest, ypred)
r2Value = r2_score(ytest, ypred)
maeValue = mean_absolute_error(ytest, ypred)

print(f'MSE: {mseValue}')
print(f'R-squared: {r2Value}')
print(f'MAE: {maeValue}')

import pandas as pd

ytest = y_test.reset_index(drop=True)
XtestScaled = pd.DataFrame(XtestScaled).reset_index(drop=True)

randomIndex = y_test.sample(5).index
actual = ytest.loc[randomIndex].tolist()
predicted = linear.predict(XtestScaled.loc[randomIndex].values)

comparison = pd.DataFrame({
    'Actual': actual,
    'Predicted': predicted
}, index=randomIndex)

print(comparison)

import matplotlib.pyplot as plt

plt.scatter(ytest, ypred, color='lightpink', label='Actual vs. Predicted')
plt.plot([min(ytest), max(ytest)], [min(ytest), max(ytest)], color='black', linestyle='--', linewidth=2, label='Line of Best Fit')
plt.xlabel('Actual Log Price')
plt.ylabel('Predicted Log Price')
plt.title('Linear Regression : Actual vs. Predicted Log Price')
plt.legend()
plt.show()

import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np

sns.set_palette("pastel")

plt.figure(figsize=(6, 6))
plt.scatter(np.arange(len(actual)), actual, color='purple', label='Actual')
plt.scatter(np.arange(len(predicted)), predicted, color='skyblue', label='Predicted')

plt.title('Comparison of Actual and Predicted Values')
plt.xlabel('Index')
plt.ylabel('Values')
plt.legend()

plt.show()

"""**Improved verssion (ON selected features)**"""

import pandas as pd
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.preprocessing import StandardScaler, PolynomialFeatures
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error


corr_matrix = df.corr()
high_corr_features = corr_matrix['log_price'].abs().sort_values(ascending=False).index
selected_features = high_corr_features[1:22]

X = df[selected_features]
y = df['log_price']
Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, test_size=0.2, random_state=42)

# Feature Scaling
scale = StandardScaler()
XtrainScaled = scale.fit_transform(Xtrain)
XtestScaled = scale.transform(Xtest)

# Feature Transformation
poly = PolynomialFeatures(degree=2)
XtrainPoly = poly.fit_transform(XtrainScaled)
XtestPoly = poly.transform(XtestScaled)

# Linear Regression Model
linear_model = LinearRegression()
linear_model.fit(XtrainPoly, ytrain)

# Evaluation
ypred = linear_model.predict(XtestPoly)
mseValue = mean_squared_error(ytest, ypred)
r2Value = r2_score(ytest, ypred)
maeValue = mean_absolute_error(ytest, ypred)

# Cross-Validation Score
cv_scores = cross_val_score(linear_model, XtrainPoly, ytrain, cv=5)

print(f'MSE: {mseValue}')
print(f'R-squared: {r2Value}')
print(f'MAE: {maeValue}')
print(f'Cross-Validation Scores: {cv_scores}')

import matplotlib.pyplot as plt

plt.scatter(ytest, ypred, color='lightpink', label='Actual vs. Predicted')
plt.plot([min(ytest), max(ytest)], [min(ytest), max(ytest)], color='black', linestyle='--', linewidth=2, label='Line of Best Fit')
plt.xlabel('Actual Log Price')
plt.ylabel('Predicted Log Price')
plt.title('Linear Regression : Actual vs. Predicted Log Price')
plt.legend()
plt.show()

import pandas as pd
XtestPoly = poly.transform(XtestScaled)

predicted = linear_model.predict(XtestPoly[randomIndex])

comparison = pd.DataFrame({
    'Actual': ytest.iloc[randomIndex].tolist(),
    'Predicted': predicted
}, index=randomIndex)

print(comparison)

import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np

sns.set_palette("pastel")

plt.figure(figsize=(6, 6))
plt.scatter(np.arange(len(actual)), actual, color='purple', label='Actual')
plt.scatter(np.arange(len(predicted)), predicted, color='skyblue', label='Predicted')

plt.title('Comparison of Actual and Predicted Values')
plt.xlabel('Index')
plt.ylabel('Values')
plt.legend()

plt.show()

"""# LASSO REGRESSION"""

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import Lasso
from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error

Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, test_size=0.2, random_state=42)

scale = StandardScaler()
XtrainScaled = scale.fit_transform(Xtrain)
XtestScaled = scale.transform(Xtest)

# 'alpha' is a hyperparameter for Lasso
lasso = Lasso(alpha=0.1)
lasso.fit(XtrainScaled, ytrain)

ypred = lasso.predict(XtestScaled)

#evalutation
mseValue = mean_squared_error(ytest, ypred)
r2Value = r2_score(ytest, ypred)
maeValue = mean_absolute_error(ytest, ypred)

print(f'MSE: {mseValue}')
print(f'R-squared: {r2Value}')
print(f'MAE: {maeValue}')

import pandas as pd

ytest = y_test.reset_index(drop=True)
XtestScaled = pd.DataFrame(XtestScaled).reset_index(drop=True)

randomIndex = ytest.sample(5).index
actual = ytest.loc[randomIndex].tolist()
predicted = lasso.predict(XtestScaled.loc[randomIndex].values)

comparison = pd.DataFrame({
    'Actual': actual,
    'Predicted': predicted
}, index=randomIndex)

print(comparison)

import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np

sns.set_palette("pastel")

plt.figure(figsize=(6, 6))
plt.scatter(np.arange(len(actual)), actual, color='skyblue', label='Actual')
plt.scatter(np.arange(len(predicted)), predicted, color='sandybrown', label='Predicted')

plt.title('Comparison of Actual and Predicted Values')
plt.xlabel('Index')
plt.ylabel('Values')
plt.legend()

plt.show()

import matplotlib.pyplot as plt

plt.scatter(ytest, ypred, color='lightpink', label='Actual vs. Predicted')
plt.plot([min(ytest), max(ytest)], [min(ytest), max(ytest)], color='black', linestyle='--', linewidth=2, label='Line of Best Fit')
plt.xlabel('Actual Log Price')
plt.ylabel('Predicted Log Price')
plt.title('Lasso Regression: Actual vs. Predicted Log Price')
plt.legend()
plt.show()

"""**TUNNING PARAMETERS**"""

import pandas as pd
from sklearn.linear_model import Lasso
from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error
from sklearn.model_selection import train_test_split, GridSearchCV


corr_matrix = df.corr().abs()
upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))


to_drop = [column for column in upper.columns if any(upper[column] > 0.95)]

df_reduced = df.drop(df[to_drop], axis=1)

target_corr = corr_matrix['log_price'].sort_values(ascending=False)
selected_features = target_corr[target_corr > 0.5].index.tolist()

X = df_reduced[selected_features]
y = df['log_price']
Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, test_size=0.2, random_state=42)

scale = StandardScaler()
XtrainScaled = scale.fit_transform(Xtrain)
XtestScaled = scale.transform(Xtest)

param_grid = {'alpha': [0.001, 0.0001, 0.01, 0.1, 1, 0.5, 10, 100]}

grid_search = GridSearchCV(Lasso(), param_grid, cv=20, scoring='r2')

grid_search.fit(XtrainScaled, ytrain)

best_alpha = grid_search.best_params_['alpha']

lasso_best = Lasso(alpha=best_alpha)
lasso_best.fit(XtrainScaled, ytrain)

ypred_best = lasso_best.predict(XtestScaled)
mse_best = mean_squared_error(ytest, ypred_best)
r2_best = r2_score(ytest, ypred_best)
mae_best = mean_absolute_error(ytest, ypred_best)

print(f'MSE (tuned): {mse_best}')
print(f'R-squared (tuned): {r2_best}')
print(f'MAE (tuned): {mae_best}')

randomIndex = np.random.choice(XtestScaled.shape[0], 5, replace=False)
actual_sample = ytest.iloc[randomIndex].tolist()
predicted_sample = lasso_best.predict(XtestScaled[randomIndex])

comparison = pd.DataFrame({
    'Actual': actual_sample,
    'Predicted': predicted_sample
}, index=randomIndex)

comparison

import matplotlib.pyplot as plt

plt.scatter(ytest, ypred, color='lightpink', label='Actual vs. Predicted')
plt.plot([min(ytest), max(ytest)], [min(ytest), max(ytest)], color='black', linestyle='--', linewidth=2, label='Line of Best Fit')
plt.xlabel('Actual Log Price')
plt.ylabel('Predicted Log Price')
plt.title('Ridge Regression: Actual vs. Predicted Log Price')
plt.legend()
plt.show()

import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np

sns.set_palette("pastel")

plt.figure(figsize=(6, 6))

plt.scatter(np.arange(len(actual_sample)), actual_sample, color='skyblue', label='Actual')

plt.scatter(np.arange(len(predicted_sample)), predicted_sample, color='sandybrown', label='Predicted')

plt.title('Comparison of Actual and Predicted Values')
plt.xlabel('Index')
plt.ylabel('Values')

plt.legend()

plt.show()

!pip install lime

from lime import lime_tabular
explainer = lime_tabular.LimeTabularExplainer(
    training_data=XtrainScaled,
    feature_names=selected_features,
    mode='regression'
)

i = 10
instance = XtestScaled[i]

exp = explainer.explain_instance(instance, lasso_best.predict, num_features=len(selected_features))

exp.show_in_notebook(show_all=False)

import pandas as pd
from lime import lime_tabular
from sklearn.linear_model import Lasso
from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.preprocessing import StandardScaler
from IPython.display import display, HTML

corr_matrix = df.corr().abs()
upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))
to_drop = [column for column in upper.columns if any(upper[column] > 0.95)]
df_reduced = df.drop(df[to_drop], axis=1)
target_corr = corr_matrix['log_price'].sort_values(ascending=False)
selected_features = target_corr[target_corr > 0.5].index.tolist()

X = df_reduced[selected_features]
y = df['log_price']
Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, test_size=0.2, random_state=42)

scale = StandardScaler()
XtrainScaled = scale.fit_transform(Xtrain)
XtestScaled = scale.transform(Xtest)

explainer = lime_tabular.LimeTabularExplainer(
    training_data=XtrainScaled,
    feature_names=selected_features,
    mode='regression'
)

clear_background = """
<style>
.lime {
    background-color: white;
}
</style>
"""

display(HTML(clear_background))

for i in range(len(XtestScaled)):
    instance = XtestScaled[i]
    exp = explainer.explain_instance(instance, lasso_best.predict, num_features=len(selected_features))
    print(f"Explaining instance {i+1}/{len(XtestScaled)}...")
    exp.show_in_notebook(show_all=False)

!pip install shap

import shap
import numpy as np
from IPython.display import display, HTML

# Initialize the SHAP explainer with the correct masker
masker = shap.maskers.Independent(data=XtrainScaled)
explainer = shap.LinearExplainer(lasso_best, masker, feature_perturbation="interventional")

# Calculate SHAP values for the test set
shap_values = explainer.shap_values(XtestScaled)

clear_background = """
<style>
.shap_html {
    background-color: white;
}
</style>
"""

display(HTML(clear_background))

# Sample 50 random indices from the test set
random_indices = np.random.choice(XtestScaled.shape[0], 50, replace=False)

# Generate and display SHAP force plots for the selected instances
for i in random_indices:
    shap.initjs()
    display(shap.force_plot(explainer.expected_value, shap_values[i], XtestScaled[i], feature_names=selected_features))

"""# RIDGE REGRESSION"""

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import Ridge
from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error

Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, test_size=0.2, random_state=42)

scale = StandardScaler()
XtrainScaled = scale.fit_transform(Xtrain)
XtestScaled = scale.transform(Xtest)

ridge = Ridge(alpha=0.001)
ridge.fit(XtrainScaled, ytrain)

# Predictions
ypred = ridge.predict(XtestScaled)

# Evaluation
mse = mean_squared_error(ytest, ypred)
r2 = r2_score(ytest, ypred)
mae = mean_absolute_error(ytest, ypred)

print(f'MSE: {mse}')
print(f'R-squared: {r2}')
print(f'MAE: {mae}')

import pandas as pd

ytest = ytest.reset_index(drop=True)
XtestScaled = pd.DataFrame(XtestScaled).reset_index(drop=True)

randomIndex = ytest.sample(5).index
actual = ytest.loc[randomIndex].tolist()
predicted = ridge.predict(XtestScaled.loc[randomIndex].values)

comparison = pd.DataFrame({
    'Actual': actual,
    'Predicted': predicted
}, index=randomIndex)

print(comparison)

import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np

sns.set_palette("pastel")

plt.figure(figsize=(6, 6))
plt.scatter(np.arange(len(actual)), actual, color='skyblue', label='Actual')
plt.scatter(np.arange(len(predicted)), predicted, color='sandybrown', label='Predicted')

plt.title('Comparison of Actual and Predicted Values')
plt.xlabel('Index')
plt.ylabel('Values')
plt.legend()

plt.show()

import matplotlib.pyplot as plt

plt.scatter(ytest, ypred, color='lightpink', label='Actual vs. Predicted')
plt.plot([min(ytest), max(ytest)], [min(ytest), max(ytest)], color='black', linestyle='--', linewidth=2, label='Line of Best Fit')
plt.xlabel('Actual Log Price')
plt.ylabel('Predicted Log Price')
plt.title('Ridge Regression: Actual vs. Predicted Log Price')
plt.legend()
plt.show()

"""**Improved with selected features**"""

import pandas as pd
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.preprocessing import StandardScaler, PolynomialFeatures
from sklearn.linear_model import RidgeCV
from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error

corr_matrix = df.corr()

high_corr_features = corr_matrix['log_price'].abs().sort_values(ascending=False).index

selected_features = high_corr_features[1:22]

X = df[selected_features]
Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, test_size=0.2, random_state=42)

scale = StandardScaler()
XtrainScaled = scale.fit_transform(Xtrain)
XtestScaled = scale.transform(Xtest)

poly = PolynomialFeatures(degree=2)
XtrainPoly = poly.fit_transform(XtrainScaled)
XtestPoly = poly.transform(XtestScaled)

ridge_cv = RidgeCV(alphas=[0.001, 0.0001, 0.01, 0.1, 1, 10, 100], cv=5)
ridge_cv.fit(XtrainPoly, ytrain)

ypred = ridge_cv.predict(XtestPoly)
mseValue = mean_squared_error(ytest, ypred)
r2Value = r2_score(ytest, ypred)
maeValue = mean_absolute_error(ytest, ypred)

cv_scores = cross_val_score(ridge_cv, XtrainPoly, ytrain, cv=5)

print(f'MSE: {mseValue}')
print(f'R-squared: {r2Value}')
print(f'MAE: {maeValue}')
print(f'Cross-Validation Scores: {cv_scores}')
print(f'Average CV Score: {cv_scores.mean()}')

import pandas as pd

ytest = ytest.reset_index(drop=True)
XtestScaled = pd.DataFrame(XtestScaled).reset_index(drop=True)

randomIndex = ytest.sample(5).index
actual = ytest.loc[randomIndex].tolist()
predicted = ridge.predict(XtestScaled.loc[randomIndex].values)

comparison = pd.DataFrame({
    'Actual': actual,
    'Predicted': predicted
}, index=randomIndex)

print(comparison)

import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np

sns.set_palette("pastel")

plt.figure(figsize=(6, 6))
plt.scatter(np.arange(len(actual)), actual, color='skyblue', label='Actual')
plt.scatter(np.arange(len(predicted)), predicted, color='sandybrown', label='Predicted')

plt.title('Comparison of Actual and Predicted Values')
plt.xlabel('Index')
plt.ylabel('Values')
plt.legend()

plt.show()

import matplotlib.pyplot as plt

plt.scatter(ytest, ypred, color='lightpink', label='Actual vs. Predicted')
plt.plot([min(ytest), max(ytest)], [min(ytest), max(ytest)], color='black', linestyle='--', linewidth=2, label='Line of Best Fit')
plt.xlabel('Actual Log Price')
plt.ylabel('Predicted Log Price')
plt.title('Ridge Regression: Actual vs. Predicted Log Price')
plt.legend()
plt.show()

"""# ELASTIC NET REGRESSION

"""

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import ElasticNet, ElasticNetCV
from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error

corr_matrix = df.corr()
high_corr_features = corr_matrix['log_price'].abs().sort_values(ascending=False).index
selected_features = high_corr_features[1:22]  # Select top 21 features excluding the target itself

# Prepare the data with the selected features
X = df[selected_features]
y = df['log_price']
Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, test_size=0.2, random_state=42)

# Standardize the features
scaler = StandardScaler()
XtrainScaled = scaler.fit_transform(Xtrain)
XtestScaled = scaler.transform(Xtest)

# Initialize the Elastic Net model with cross-validated hyperparameters
elastic_cv = ElasticNetCV(alphas=[0.001, 0.01, 0.1, 1, 10], l1_ratio=[0.1, 0.5, 0.7, 0.9, 0.95, 1], cv=5)
elastic_cv.fit(XtrainScaled, ytrain)

# Retrieve the best alpha and l1_ratio
best_alpha = elastic_cv.alpha_
best_l1_ratio = elastic_cv.l1_ratio_

# Fit the Elastic Net model with the best hyperparameters
elasticnet_optimized = ElasticNet(alpha=best_alpha, l1_ratio=best_l1_ratio)
elasticnet_optimized.fit(XtrainScaled, ytrain)

# Predict and evaluate the model
ypred_optimized = elasticnet_optimized.predict(XtestScaled)
mse_optimized = mean_squared_error(ytest, ypred_optimized)
r2_optimized = r2_score(ytest, ypred_optimized)
mae_optimized = mean_absolute_error(ytest, ypred_optimized)

# Print the evaluation metrics
print(f'MSE (Optimized): {mse_optimized}')
print(f'R-squared (Optimized): {r2_optimized}')
print(f'MAE (Optimized): {mae_optimized}')

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np

ytest = ytest.reset_index(drop=True)
XtestScaled = pd.DataFrame(XtestScaled).reset_index(drop=True)

randomIndex = np.random.choice(ytest.index, 5, replace=False)
actual = ytest.loc[randomIndex].tolist()
predicted = elasticnet_optimized.predict(XtestScaled.loc[randomIndex].values)

comparison = pd.DataFrame({
    'Actual': actual,
    'Predicted': predicted
}, index=randomIndex)

print(comparison)

sns.set_palette("pastel")

plt.figure(figsize=(10, 6))

plt.scatter(np.arange(len(actual)), actual, color='skyblue', label='Actual')

plt.scatter(np.arange(len(predicted)), predicted, color='sandybrown', label='Predicted')

plt.title('Comparison of Actual and Predicted Values')
plt.xlabel('Index')
plt.ylabel('Values')

plt.legend()

plt.show()

import matplotlib.pyplot as plt
import numpy as np

plt.scatter(ytest, ypred_optimized, color='lightpink', label='Actual vs. Predicted')
coefficients = np.polyfit(ytest, ypred_optimized, 1)
polynomial = np.poly1d(coefficients)
y_fit = polynomial(ytest)

plt.plot(ytest, y_fit, color='black', linestyle='--', linewidth=2, label='Line of Best Fit')

plt.xlabel('Actual Log Price')
plt.ylabel('Predicted Log Price')
plt.title('Elastic Net Regression: Actual vs. Predicted Log Price')
plt.legend()
plt.show()

!pip install shap

pip install lime

import pandas as pd
df=pd.read_csv("processed_data.csv")
df

"""# **Random Forest**"""

from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error
import pandas as pd

selected_features = ['room_type_encoded', 'accommodates', 'bedrooms', 'beds', 'bathrooms',
                     'cancellation_policy_encoded', 'cleaning_fee', 'bed_type_encoded',
                     'amenities', 'review_scores_rating', 'host_since_days', 'longitude',
                     'property_type_encoded', 'instant_bookable', 'number_of_reviews',
                     'first_review_days', 'city_encoded', 'neighbourhood_encoded']

X = df[selected_features]  # Features
y = df['log_price']  # Target variable

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

from sklearn.model_selection import GridSearchCV

# Define the parameter grid to search over
param_grid = {
    'n_estimators': [100, 200, 300],
    'max_depth': [None, 10, 20],
    'min_samples_split': [2, 5, 10],
    'min_samples_leaf': [1, 2, 4]
}

# Initialize RandomForestRegressor
rf_model = RandomForestRegressor(random_state=42)

# Initialize GridSearchCV
grid_search = GridSearchCV(estimator=rf_model, param_grid=param_grid,
                           cv=5, scoring='r2', n_jobs=-1)

# Perform grid search
grid_search.fit(X_train, y_train)

# Best hyperparameters
best_params = grid_search.best_params_
print("Best Hyperparameters:", best_params)

# Predict using the best model
best_rf_model = grid_search.best_estimator_
y_pred = best_rf_model.predict(X_test)

# Evaluate the model
r2 = r2_score(y_test, y_pred)
mae = mean_absolute_error(y_test, y_pred)
mse = mean_squared_error(y_test, y_pred)

print("R2 Score (After Tuning):", r2)
print("Mean Absolute Error (MAE) (After Tuning):", mae)
print("Mean Squared Error (MSE) (After Tuning):", mse)

"""## Prediction On Test Set"""

import random
random.seed(42)
sample_indices = random.sample(range(len(X_test)), 5)

sample_X = X_test.iloc[sample_indices]
sample_y_actual = y_test.iloc[sample_indices]

sample_y_pred = best_rf_model.predict(sample_X)

results_df = pd.DataFrame({
    'Actual Log Price': sample_y_actual.values,
    'Predicted Log Price': sample_y_pred
})

print("Random Sample: Actual vs. Predicted Log Prices")
print(results_df)

"""## Line of best fit"""

import matplotlib.pyplot as plt
import numpy as np

# Scatter plot of predicted vs actual values
plt.figure(figsize=(8, 6))
plt.scatter(y_test, y_pred, alpha=0.5)
plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], 'r--', lw=2)
plt.xlabel("Actual Log Price")
plt.ylabel("Predicted Log Price")
plt.title("Random Forest: Scatter Plot of Predicted vs Actual Values")
plt.show()

"""### **Residual Plot**"""

residuals = y_test - y_pred
plt.figure(figsize=(8, 6))
plt.scatter(y_pred, residuals, alpha=0.5)
plt.axhline(y=0, color='r', linestyle='--', lw=2)  # Plotting the horizontal line at y=0
plt.xlabel("Predicted Log Price")
plt.ylabel("Residuals")
plt.title("Residual Plot")
plt.show()

import numpy as np

metrics = ['R2 Score', 'MAE', 'MSE']
scores = [r2, mae, mse]

plt.figure(figsize=(8, 6))
plt.bar(metrics, scores, color=['b', 'g', 'r'])
plt.ylabel("Score")
plt.title("Model Evaluation Metrics")
plt.show()

"""# **Gradient Boosting Regressor**"""

from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.ensemble import GradientBoostingRegressor
from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error
import pandas as pd

# Define selected features
selected_features = ['room_type_encoded', 'accommodates', 'bedrooms', 'beds', 'bathrooms',
                     'cancellation_policy_encoded', 'cleaning_fee', 'bed_type_encoded',
                     'amenities', 'review_scores_rating', 'host_since_days', 'longitude',
                     'property_type_encoded', 'instant_bookable', 'number_of_reviews',
                     'first_review_days', 'city_encoded', 'neighbourhood_encoded']

# Prepare features and target variable
X = df[selected_features]
y = df['log_price']

# Split data into training and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Define the parameter grid to search over
gb_model = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, random_state=42)

# Fit the model on the training data
gb_model.fit(X_train, y_train)

# Make predictions on the test data
y_pred = gb_model.predict(X_test)

# Evaluate model performance
r2 = r2_score(y_test, y_pred)
mae = mean_absolute_error(y_test, y_pred)
mse = mean_squared_error(y_test, y_pred)

# Print the evaluation metrics
print("Gradient Boosting Regressor Performance:")
print("R2 Score:", r2)
print("Mean Absolute Error (MAE):", mae)
print("Mean Squared Error (MSE):", mse)

"""## Prediction on Test Set"""

import random
random.seed(42)
sample_indices = random.sample(range(len(X_test)), 5)

sample_X = X_test.iloc[sample_indices]
sample_y_actual = y_test.iloc[sample_indices]

sample_y_pred = gb_model.predict(sample_X)

results_df = pd.DataFrame({
    'Actual Log Price': sample_y_actual.values,
    'Predicted Log Price': sample_y_pred
})

print("Random Sample: Actual vs. Predicted Log Prices")
print(results_df)

import matplotlib.pyplot as plt
import numpy as np

# Scatter plot of predicted vs actual values
plt.figure(figsize=(8, 6))
plt.scatter(y_test, y_pred, color='salmon', alpha=0.5)
plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], 'r--', lw=2)  # Plotting the diagonal line of equality
plt.xlabel("Actual Log Price")
plt.ylabel("Predicted Log Price")
plt.title("Gradient Booster: Scatter Plot of Predicted vs Actual Values")
plt.show()

"""# **XGBoost**"""

from sklearn.model_selection import train_test_split
from xgboost import XGBRegressor
from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error
import pandas as pd


selected_features = ['room_type_encoded', 'accommodates', 'bedrooms', 'beds', 'bathrooms',
                     'cancellation_policy_encoded', 'cleaning_fee', 'bed_type_encoded',
                     'amenities', 'review_scores_rating', 'host_since_days', 'longitude',
                     'property_type_encoded', 'instant_bookable', 'number_of_reviews',
                     'first_review_days', 'city_encoded', 'neighbourhood_encoded']

X = df[selected_features]  # Features
y = df['log_price']  # Target variable

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
xgb_model = XGBRegressor(n_estimators=100, learning_rate=0.1, random_state=42)
xgb_model.fit(X_train, y_train)
y_pred = xgb_model.predict(X_test)

# Evaluate model performance
r2 = r2_score(y_test, y_pred)
mae = mean_absolute_error(y_test, y_pred)
mse = mean_squared_error(y_test, y_pred)

# Print the evaluation metrics
print("XGBoost Regressor Performance:")
print("R2 Score:", r2)
print("Mean Absolute Error (MAE):", mae)
print("Mean Squared Error (MSE):", mse)

"""## Prediction on Test Set"""

import random
random.seed(42)
sample_indices = random.sample(range(len(X_test)), 5)

sample_X = X_test.iloc[sample_indices]
sample_y_actual = y_test.iloc[sample_indices]

sample_y_pred = xgb_model.predict(sample_X)

results_df = pd.DataFrame({
    'Actual Log Price': sample_y_actual.values,
    'Predicted Log Price': sample_y_pred
})

print("Random Sample: Actual vs. Predicted Log Prices")
print(results_df)

import matplotlib.pyplot as plt
import numpy as np

# Scatter plot of predicted vs actual values
plt.figure(figsize=(8, 6))
plt.scatter(y_test, y_pred, color='#0307fc', alpha=0.5)
plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], 'r--', lw=2)  # Plotting the diagonal line of equality
plt.xlabel("Actual Log Price")
plt.ylabel("Predicted Log Price")
plt.title("XGBoost: Scatter Plot of Predicted vs Actual Values")
plt.show()

"""# **LightGM (Light Gradient Boosting Machine)**"""

from sklearn.model_selection import train_test_split
from lightgbm import LGBMRegressor
from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error
import pandas as pd

selected_features = ['room_type_encoded', 'accommodates', 'bedrooms', 'beds', 'bathrooms',
                     'cancellation_policy_encoded', 'cleaning_fee', 'bed_type_encoded',
                     'amenities', 'review_scores_rating', 'host_since_days', 'longitude',
                     'property_type_encoded', 'instant_bookable', 'number_of_reviews',
                     'first_review_days', 'city_encoded', 'neighbourhood_encoded']

X = df[selected_features]  # Features
y = df['log_price']  # Target variable

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
lgbm_model = LGBMRegressor(n_estimators=100, learning_rate=0.1, random_state=42)

lgbm_model.fit(X_train, y_train)

y_pred = lgbm_model.predict(X_test)

# Evaluate model performance
r2 = r2_score(y_test, y_pred)
mae = mean_absolute_error(y_test, y_pred)
mse = mean_squared_error(y_test, y_pred)

# Print the evaluation metrics
print("LightGBM Regressor Performance:")
print("R2 Score:", r2)
print("Mean Absolute Error (MAE):", mae)
print("Mean Squared Error (MSE):", mse)

"""# Prediction on Test Set"""

import random
random.seed(42)
sample_indices = random.sample(range(len(X_test)), 5)

sample_X = X_test.iloc[sample_indices]
sample_y_actual = y_test.iloc[sample_indices]

sample_y_pred = lgbm_model.predict(sample_X)

results_df = pd.DataFrame({
    'Actual Log Price': sample_y_actual.values,
    'Predicted Log Price': sample_y_pred
})

print("Random Sample: Actual vs. Predicted Log Prices")
print(results_df)

"""# Visual Plots using SHAP"""

import shap

# Create the explainer with check_additivity=False
explainer = shap.TreeExplainer(lgbm_model, X_train)

# Compute SHAP values for the test set
shap_values = explainer.shap_values(X_test, check_additivity=False)

"""## Dependancy Plot"""

# Plot SHAP dependence plot for a specific feature (e.g., 'accommodates')
shap.dependence_plot('amenities', shap_values, X_test)

"""## LIME"""

from lime.lime_tabular import LimeTabularExplainer

explainer = LimeTabularExplainer(X_train.values, feature_names=X_train.columns, mode='regression')

idx = 0
explanation = explainer.explain_instance(X_test.iloc[idx].values, lgbm_model.predict)

# Visualize LIME explanation
explanation.show_in_notebook()

# Evaluate model performance
r2 = r2_score(y_test, y_pred)
mae = mean_absolute_error(y_test, y_pred)
mse = mean_squared_error(y_test, y_pred)

# Print evaluation metrics
print("R2 Score:", r2)
print("Mean Absolute Error (MAE):", mae)
print("Mean Squared Error (MSE):", mse)

# Visualize SHAP summary plot
shap.summary_plot(shap_values, X_test, plot_type="bar")

# Explain an individual prediction using LIME
idx = 0
explanation = explainer.explain_instance(X_test.iloc[idx].values, lgbm_model.predict)
explanation.show_in_notebook()

import matplotlib.pyplot as plt
import numpy as np

# Scatter plot of predicted vs actual values
plt.figure(figsize=(8, 6))
plt.scatter(y_test, y_pred, color='#03a856', alpha=0.5)
plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], 'r--', lw=2)  # Plotting the diagonal line of equality
plt.xlabel("Actual Log Price")
plt.ylabel("Predicted Log Price")
plt.title("XGBoost: Scatter Plot of Predicted vs Actual Values")
plt.show()

"""# **CatBoost**"""

pip install catboost

from sklearn.model_selection import train_test_split
from catboost import CatBoostRegressor
from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error
import pandas as pd

selected_features = ['room_type_encoded', 'accommodates', 'bedrooms', 'beds', 'bathrooms',
                     'cancellation_policy_encoded', 'cleaning_fee', 'bed_type_encoded',
                     'amenities', 'review_scores_rating', 'host_since_days', 'longitude',
                     'property_type_encoded', 'instant_bookable', 'number_of_reviews',
                     'first_review_days', 'city_encoded', 'neighbourhood_encoded']

X = df[selected_features]  # Features
y = df['log_price']  # Target variable

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
catboost_model = CatBoostRegressor(iterations=100, learning_rate=0.1, random_state=42)

catboost_model.fit(X_train, y_train, verbose=False)
y_pred = catboost_model.predict(X_test)

# Evaluate model performance
r2 = r2_score(y_test, y_pred)
mae = mean_absolute_error(y_test, y_pred)
mse = mean_squared_error(y_test, y_pred)

# Print the evaluation metrics
print("CatBoost Regressor Performance:")
print("R2 Score:", r2)
print("Mean Absolute Error (MAE):", mae)
print("Mean Squared Error (MSE):", mse)

"""## Prediction on Test Set"""

import random
random.seed(42)
sample_indices = random.sample(range(len(X_test)), 5)

sample_X = X_test.iloc[sample_indices]
sample_y_actual = y_test.iloc[sample_indices]

sample_y_pred = catboost_model.predict(sample_X)

results_df = pd.DataFrame({
    'Actual Log Price': sample_y_actual.values,
    'Predicted Log Price': sample_y_pred
})

print("Random Sample: Actual vs. Predicted Log Prices")
print(results_df)

import matplotlib.pyplot as plt
import numpy as np

# Scatter plot of predicted vs actual values
plt.figure(figsize=(8, 6))
plt.scatter(y_test, y_pred, color='#de2f9b', alpha=0.5)
plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], 'r--', lw=2)  # Plotting the diagonal line of equality
plt.xlabel("Actual Log Price")
plt.ylabel("Predicted Log Price")
plt.title("XGBoost: Scatter Plot of Predicted vs Actual Values")
plt.show()

"""## **Decision tree regression**"""

X = df[selected_features_filter]
y = df['log_price']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Initialize a Decision Tree Regressor
dt = DecisionTreeRegressor()

dt.fit(X_train, y_train)

# Evaluate performance on test data using selected features
y_pred = dt.predict(X_test)

mse = mean_squared_error(y_test, y_pred)
print("Mean Squared Error:", mse)
mae = mean_absolute_error(y_test, y_pred)
print("Mean Absolute Error:", mae)
r2 = r2_score(y_test, y_pred)
print("R-squared:", r2)

# Perform cross-validation for MSE
cv_scores_mse = cross_val_score(dt, X, y, cv=5, scoring='neg_mean_squared_error')
mse_scores = -cv_scores_mse
print("Cross-Validation MSE Scores:", min(mse_scores))

# Perform cross-validation for MAE
cv_scores_mae = cross_val_score(dt, X, y, cv=5, scoring='neg_mean_absolute_error')
mae_scores = -cv_scores_mae
print("Cross-Validation MAE Scores:", min(mae_scores))

# Perform cross-validation for R2
cv_scores_r2 = cross_val_score(dt, X, y, cv=5, scoring='r2')
print("Cross-Validation R2 Scores:", max(cv_scores_r2))

# Define a custom scoring function for RMSE
def rmse(y_true, y_pred):
    return np.sqrt(mean_squared_error(y_true, y_pred))

# Create a scorer object for RMSE
rmse_scorer = make_scorer(rmse, greater_is_better=False)

# Perform cross-validation for RMSE
cv_scores_rmse = cross_val_score(dt, X, y, cv=5, scoring=rmse_scorer)
rmse_scores = -cv_scores_rmse
print("Cross-Validation RMSE Scores:", min(rmse_scores))

plt.figure(figsize=(10, 6))
plt.scatter(y_test, y_pred, color='skyblue', alpha=0.5)
plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], '--', color='red')  # Diagonal line representing perfect prediction
plt.title('Decision Tree: Scatter plot of Actual vs Predicted Log Price')
plt.xlabel('Actual Log Price')
plt.ylabel('Predicted Log Price')
plt.grid()
plt.show()

sns.histplot(y_test - y_pred, bins = 50)
plt.title('Error variance')
plt.show()

import random
random.seed(42)
sample_indices = random.sample(range(len(X_test)), 5)

sample_X = X_test.iloc[sample_indices]
sample_y_actual = y_test.iloc[sample_indices]

sample_y_pred = dt.predict(sample_X)

results_df = pd.DataFrame({
    'Actual Log Price': sample_y_actual.values,
    'Predicted Log Price': sample_y_pred
})

print("Random Sample: Actual vs. Predicted Log Prices")
print(results_df)

"""## KNN"""

# Initialize a k-Nearest Neighbors Regressor
knn = KNeighborsRegressor()

knn.fit(X_train, y_train)

# Predict on the test set
y_pred = knn.predict(X_test)

# Evaluate performance
mse = mean_squared_error(y_test, y_pred)
print("Mean Squared Error:", mse)

mae = mean_absolute_error(y_test, y_pred)
print("Mean Absolute Error:", mae)

r2 = r2_score(y_test, y_pred)
print("R-squared:", r2)

# Perform cross-validation for MSE
cv_scores_mse = cross_val_score(knn, X, y, cv=5, scoring='neg_mean_squared_error')
mse_scores = -cv_scores_mse
print("Cross-Validation MSE Scores:", min(mse_scores))

# Perform cross-validation for MAE
cv_scores_mae = cross_val_score(knn, X, y, cv=5, scoring='neg_mean_absolute_error')
mae_scores = -cv_scores_mae
print("Cross-Validation MAE Scores:", min(mae_scores))

# Perform cross-validation for R2
cv_scores_r2 = cross_val_score(knn, X, y, cv=5, scoring='r2')
print("Cross-Validation R2 Scores:", max(cv_scores_r2))

# Define a custom scoring function for RMSE
def rmse(y_true, y_pred):
    return np.sqrt(mean_squared_error(y_true, y_pred))

# Create a scorer object for RMSE
rmse_scorer = make_scorer(rmse, greater_is_better=False)

# Perform cross-validation for RMSE
cv_scores_rmse = cross_val_score(knn, X, y, cv=5, scoring=rmse_scorer)
rmse_scores = -cv_scores_rmse
print("Cross-Validation RMSE Scores:", min(rmse_scores))

plt.figure(figsize=(10, 6))
plt.scatter(y_test, y_pred, color='skyblue', alpha=0.5)
plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], '--', color='red')  # Diagonal line representing perfect prediction
plt.title('KNN: Scatter plot of Actual vs Predicted Log Price')
plt.xlabel('Actual Log Price')
plt.ylabel('Predicted Log Price')
plt.grid()
plt.show()

sns.histplot(y_test - y_pred, bins = 50)
plt.title('Error variance')
plt.show()

import random
random.seed(42)
sample_indices = random.sample(range(len(X_test)), 5)

sample_X = X_test.iloc[sample_indices]
sample_y_actual = y_test.iloc[sample_indices]

sample_y_pred = knn.predict(sample_X)

results_df = pd.DataFrame({
    'Actual Log Price': sample_y_actual.values,
    'Predicted Log Price': sample_y_pred
})

print("Random Sample: Actual vs. Predicted Log Prices")
print(results_df)

"""## SVM"""

# Select features using Mutual Information
#selector = SelectKBest(score_func=mutual_info_regression, k=19)
#X_train_selected = selector.fit_transform(X_train, y_train)
#X_test_selected = selector.transform(X_test)

# Initialize a Support Vector Machine Regressor
svm = SVR()

# Train SVM on the selected features
svm.fit(X_train, y_train)

# Predict on the test set
y_pred = svm.predict(X_test)

# Evaluate performance
mse = mean_squared_error(y_test, y_pred)
print("Mean Squared Error with selected features:", mse)

mae = mean_absolute_error(y_test, y_pred)
print("Mean Absolute Error with selected features:", mae)

r2 = r2_score(y_test, y_pred)
print("R-squared with selected features:", r2)

plt.figure(figsize=(10, 6))
plt.scatter(y_test, y_pred, color='skyblue', alpha=0.5)
plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], '--', color='red')  # Diagonal line representing perfect prediction
plt.title('SVM Regression: Scatter plot of Actual vs Predicted Log Price')
plt.xlabel('Actual Log Price')
plt.ylabel('Predicted Log Price')
plt.grid()
plt.show()

sns.histplot(y_test - y_pred, bins = 50)
plt.title('Error variance')
plt.show()

import random
random.seed(42)
sample_indices = random.sample(range(len(X_test)), 5)

sample_X = X_test.iloc[sample_indices]
sample_y_actual = y_test.iloc[sample_indices]

sample_y_pred = svm.predict(sample_X)

results_df = pd.DataFrame({
    'Actual Log Price': sample_y_actual.values,
    'Predicted Log Price': sample_y_pred
})

print("Random Sample: Actual vs. Predicted Log Prices")
print(results_df)

"""## Bayesian Linear Regression"""

# Initialize Bayesian Linear Regression
bayesian_reg = BayesianRidge()

bayesian_reg.fit(X_train, y_train)
y_pred = bayesian_reg.predict(X_test)

mse = mean_squared_error(y_test, y_pred)
print("Mean Squared Error:", mse)

mae = mean_absolute_error(y_test, y_pred)
print("Mean Absolute Error:", mae)

r2 = r2_score(y_test, y_pred)
print("R-squared:", r2)

# Define a custom scoring function for RMSE
def rmse(y_true, y_pred):
    return np.sqrt(mean_squared_error(y_true, y_pred))

# Create a scorer object for RMSE
rmse_scorer = make_scorer(rmse, greater_is_better=False)

# Perform cross-validation for RMSE
cv_scores_rmse = cross_val_score(bayesian_reg, X, y, cv=5, scoring=rmse_scorer)
rmse_scores = -cv_scores_rmse
print("Cross-Validation RMSE Scores:", min(rmse_scores))

plt.figure(figsize=(10, 6))
plt.scatter(y_test, y_pred, color='skyblue', alpha=0.5)
plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], '--', color='red')  # Diagonal line representing perfect prediction
plt.title('Bayesian Linear Regression: Scatter plot of Actual vs Predicted Log Price')
plt.xlabel('Actual Log Price')
plt.ylabel('Predicted Log Price')
plt.grid()
plt.show()

sns.histplot(y_test - y_pred, bins = 50)
plt.title('Error variance')
plt.show()

import random
random.seed(42)
sample_indices = random.sample(range(len(X_test)), 5)

sample_X = X_test.iloc[sample_indices]
sample_y_actual = y_test.iloc[sample_indices]

sample_y_pred = bayesian_reg.predict(sample_X)

results_df = pd.DataFrame({
    'Actual Log Price': sample_y_actual.values,
    'Predicted Log Price': sample_y_pred
})

print("Random Sample: Actual vs. Predicted Log Prices")
print(results_df)

import shap

# Create a SHAP explainer object
explainer = shap.Explainer(bayesian_reg, X_train)

# Calculate SHAP values
shap_values = explainer.shap_values(X_test)

# Plot SHAP summary plot
shap.summary_plot(shap_values, X_test)

"""# **Final Comparison**"""

import pandas as pd

# Define the model results as a dictionary
model_results = {
    'Model': ['SVR', 'SVR (Optimized)', 'Linear Regression', 'Linear Regression (Selected Features)',
              'Lasso Regression', 'Lasso Regression (Optimized)', 'Ridge Regression',
              'Ridge Regression (Selected Features)', 'Elastic Net Regression (Optimized)',
              'Random Forest', 'Gradient Boosting Regressor', 'XGBoost', 'LightGBM', 'CatBoost',
              'Decision Tree', 'KNN', 'SVM', 'Bayesian Linear Regression'],
    'MSE': [0.2214, 0.2055, 0.2204, 0.1996, 0.2491, 8.96e-09, 0.2264, 0.1982, 0.2263,
            0.1760, 0.1765, 0.1668, 0.1659, 0.1751, 0.3774, 0.5939, 0.5041, 0.2348],
    'R-squared': [0.5387, 0.5718, 0.5409, 0.5841, 0.4811, 1.0000, 0.5283, 0.5871, 0.5286,
                   0.6592, 0.6583, 0.6770, 0.6786, 0.6608, 0.2691, -0.1501, 0.0239, 0.5453],
    'MAE': [0.3544, 0.3485, 0.3572, 0.3421, 0.3827, 7.45e-05, 0.3618, 0.3422, 0.3619,
            0.3128, 0.3172, 0.3065, 0.3049, 0.3147, 0.4478, 0.6115, 0.5552, 0.3695]
}

# Create a DataFrame from the model results dictionary
results_df = pd.DataFrame(model_results)

# Display the DataFrame
print(results_df)